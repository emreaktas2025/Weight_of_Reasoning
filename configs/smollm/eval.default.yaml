seed: 42

models:
  - configs/smollm/models/smollm-135m.yaml
  - configs/smollm/models/smollm-350m.yaml
  - configs/smollm/models/smollm-1.7b.yaml

datasets:
  reasoning:
    gsm8k: 800
    strategyqa: 400
  control:
    wiki: 1200

# Temperature and generation settings
temperature: 0.2
max_new_tokens: 64
top_p: 1.0

# Windowing and reasoning detection
windowing_mode: auto_no_answer
reasoning_window_length: 32

# Metrics to compute
metrics: [REV, APL, APE, SIB]

# Baseline features for comparison
baselines:
  features: [token_len, avg_logprob, perplexity, cot_len]
  model: logistic_regression

# Statistical analysis
statistics:
  bootstrap_samples: 10000
  confidence_level: 0.95
  partial_corr_controls: [token_len, ppl]

# Output settings
output_dir: experiments
plots_dir: experiments/figures
cache_dir: cache/smollm_activations

# Hardware optimization
runtime:
  use_gpu: true
  torch_dtype: bfloat16
  parallel_workers: 2
  max_memory_gb: 24

# Reproducibility
reproduce_iteration: null  # Set to iteration_XXX to reproduce
save_activations: true
save_cache: true
