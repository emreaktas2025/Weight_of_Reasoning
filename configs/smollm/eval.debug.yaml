seed: 42

models:
  - configs/smollm/models/smollm-135m.yaml

datasets:
  reasoning:
    gsm8k: 10
    strategyqa: 10
  control:
    wiki: 20

# Temperature and generation settings
temperature: 0.2
max_new_tokens: 32
top_p: 1.0

# Windowing and reasoning detection
windowing_mode: auto_no_answer
reasoning_window_length: 16

# Metrics to compute
metrics: [REV, APL, APE, SIB]

# Baseline features for comparison
baselines:
  features: [token_len, avg_logprob, perplexity, cot_len]
  model: logistic_regression

# Statistical analysis
statistics:
  bootstrap_samples: 1000  # Reduced for debug
  confidence_level: 0.95
  partial_corr_controls: [token_len, ppl]

# Output settings
output_dir: experiments
plots_dir: experiments/figures
cache_dir: cache/smollm_activations

# Hardware optimization
runtime:
  use_gpu: true
  torch_dtype: bfloat16
  parallel_workers: 1
  max_memory_gb: 8

# Reproducibility
reproduce_iteration: null
save_activations: false  # Skip for debug
save_cache: false
