{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 5 NeurIPS Analysis\n",
        "\n",
        "This notebook analyzes the Phase 5 evaluation results across three models:\n",
        "- Pythia-70M (70M parameters)\n",
        "- Pythia-410M (405M parameters)  \n",
        "- Llama-3.2-1B (1.5B parameters)\n",
        "\n",
        "We examine:\n",
        "1. Scaling behavior of REV metric\n",
        "2. Metric correlations\n",
        "3. Distributional differences across models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Set style for publication-quality figures\n",
        "plt.style.use('seaborn-v0_8-paper')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"✅ Libraries imported\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n",
        "\n",
        "Load metrics from all three models and combine into a single DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load metrics from all models\n",
        "base_path = Path(\"../reports/phase5\")\n",
        "\n",
        "models = {\n",
        "    \"Pythia-70M\": {\"file\": \"pythia-70m_metrics.csv\", \"params\": 70_463_616},\n",
        "    \"Pythia-410M\": {\"file\": \"pythia-410m_metrics.csv\", \"params\": 405_283_968},\n",
        "    \"Llama-3.2-1B\": {\"file\": \"llama3-1b_metrics.csv\", \"params\": 1_498_789_120}\n",
        "}\n",
        "\n",
        "# Load and combine data\n",
        "dfs = []\n",
        "for model_name, info in models.items():\n",
        "    df = pd.read_csv(base_path / info[\"file\"])\n",
        "    df['model'] = model_name\n",
        "    df['n_params'] = info['params']\n",
        "    dfs.append(df)\n",
        "\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "print(f\"✅ Loaded {len(combined_df)} samples across {len(models)} models\")\n",
        "print(f\"   Metrics: {[c for c in combined_df.columns if c.isupper()]}\")\n",
        "print(f\"\\nSample distribution:\")\n",
        "print(combined_df.groupby(['model', 'label']).size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Summary Statistics\n",
        "\n",
        "Compute mean ± std for key metrics across models and conditions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute summary statistics\n",
        "metrics = ['AE', 'APE', 'APL', 'CUD', 'SIB', 'FL', 'REV']\n",
        "\n",
        "summary = combined_df.groupby(['model', 'label'])[metrics].agg(['mean', 'std'])\n",
        "print(\"=\"*80)\n",
        "print(\"Summary Statistics (mean ± std)\")\n",
        "print(\"=\"*80)\n",
        "print(summary.round(4))\n",
        "\n",
        "# Compute AUROC for REV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"AUROC (REV vs label)\")\n",
        "print(\"=\"*80)\n",
        "for model_name in combined_df['model'].unique():\n",
        "    model_df = combined_df[combined_df['model'] == model_name]\n",
        "    if len(model_df['label_num'].unique()) >= 2:\n",
        "        auroc = roc_auc_score(model_df['label_num'], model_df['REV'])\n",
        "        print(f\"{model_name:20s}: {auroc:.4f}\")\n",
        "    else:\n",
        "        print(f\"{model_name:20s}: N/A (single class)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Figure 1: Scaling Curve\n",
        "\n",
        "**REV Mean vs Log(Model Parameters)**\n",
        "\n",
        "Shows how the REV metric scales with model size, demonstrating systematic patterns in reasoning effort across model scales.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directory\n",
        "output_dir = Path(\"../reports/figs_paper\")\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Figure 1: Scaling Curve\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "# Compute mean REV per model\n",
        "scaling_data = combined_df.groupby(['model', 'n_params'])['REV'].mean().reset_index()\n",
        "scaling_data['log_params'] = np.log10(scaling_data['n_params'])\n",
        "\n",
        "# Plot\n",
        "ax.scatter(scaling_data['log_params'], scaling_data['REV'], \n",
        "          s=150, alpha=0.7, edgecolors='black', linewidth=1.5)\n",
        "\n",
        "# Fit trend line\n",
        "z = np.polyfit(scaling_data['log_params'], scaling_data['REV'], 1)\n",
        "p = np.poly1d(z)\n",
        "x_line = np.linspace(scaling_data['log_params'].min(), scaling_data['log_params'].max(), 100)\n",
        "ax.plot(x_line, p(x_line), 'r--', alpha=0.5, linewidth=2, \n",
        "       label=f'Trend: y={z[0]:.3f}x+{z[1]:.3f}')\n",
        "\n",
        "# Annotate points\n",
        "for _, row in scaling_data.iterrows():\n",
        "    ax.annotate(row['model'], (row['log_params'], row['REV']),\n",
        "               xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
        "\n",
        "ax.set_xlabel('log₁₀(Parameters)', fontweight='bold')\n",
        "ax.set_ylabel('REV Score', fontweight='bold')\n",
        "ax.set_title('Scaling: REV vs Model Size', fontweight='bold', pad=15)\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"scaling_curve_analysis.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Figure 1 saved to reports/figs_paper/scaling_curve_analysis.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Figure 2: Metric Correlations\n",
        "\n",
        "**Correlation Matrix Among All Metrics**\n",
        "\n",
        "Examines inter-metric relationships to understand which aspects of reasoning effort are correlated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Figure 2: Correlation Heatmap\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr_matrix = combined_df[metrics].corr()\n",
        "\n",
        "# Plot heatmap\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
        "           center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n",
        "           vmin=-1, vmax=1, ax=ax)\n",
        "\n",
        "ax.set_title('Metric Correlation Matrix', fontweight='bold', pad=15)\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"metric_correlations.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Figure 2 saved to reports/figs_paper/metric_correlations.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Figure 3: REV Distribution\n",
        "\n",
        "**REV Score Distribution by Model**\n",
        "\n",
        "Visualizes how REV scores are distributed across models, with separation between reasoning and control tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Figure 3: REV Distribution Violin Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# Create violin plot\n",
        "sns.violinplot(data=combined_df, x='model', y='REV', hue='label', \n",
        "              split=True, inner='quartile', ax=ax)\n",
        "\n",
        "ax.set_xlabel('Model', fontweight='bold')\n",
        "ax.set_ylabel('REV Score', fontweight='bold')\n",
        "ax.set_title('REV Distribution by Model and Task Type', fontweight='bold', pad=15)\n",
        "ax.legend(title='Task Type', loc='best')\n",
        "ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(output_dir / \"rev_distribution.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Figure 3 saved to reports/figs_paper/rev_distribution.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "All figures have been generated and saved to `reports/figs_paper/`:\n",
        "1. **scaling_curve_analysis.png** - REV scaling with model size\n",
        "2. **metric_correlations.png** - Inter-metric correlation matrix  \n",
        "3. **rev_distribution.png** - REV distribution by model and task type\n",
        "\n",
        "These figures are ready for inclusion in the NeurIPS submission.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
